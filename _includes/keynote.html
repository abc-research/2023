<!-- About Section -->
    <section id="keynote">
        <div class="container">
            <div>
                <div class="col-lg-12 text-center">
                    <h2>Keynote</h2>
                    <hr class="star-primary">
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12">
                  {% for keynote in site.keynotes %}
                    <img src="http://www.schuller.it/bws/wp-content/uploads/2019/08/cropped-m29tWAORJY1N1QBkxkA_thumb_4a56.jpg" height=250"/>
                    <h3>Björn W. Schuller, Fellow IEEE</h3>
                    <p>Imperial College London / UK and University of Augsburg / Germany</p>
                    <h4>Multimodal Sentiment Analysis: Explore the No Pain, Big Gain Shortcut</h4>
                    <p>Multimodal Sentiment Analysis usually comes at massive cravings for labelled data. And, this data is best digested by deep nets well prepared by expert chefs who know their job all too well. For each modality flavour such as audio, text, video, or even physiology, a different recipe is best suited, and this is best topped by some fancy well-fitting multimodal fusion layers or techniques. This makes one wonder if there was any short-cut to perfect Multimodal Sentiment Analysis ideally saturating with little portions of data and preparable even by the domain layman. In other words: Can we solve sentiment analysis with minimal labelling effort and some black-box AI that takes it all from there, even if the data is largely heterogenous in terms of involved modalities. This talk invites to explore such an avenue with the steps of self-learning representations, coupling analysis and synthesis of sentiments for data augmentation, and autonomously learning reinforced, cross-modally, and self-supervised at scale. It will be garnished by insights into recent challenges organised by the presenter including MuSe and Interspeech ComParE. If all goes well, we shall arrive soon at instant multimodal sentiment analysis that fully satisfies.</p>
                    <h5>Björn W. Schuller</h5>
                    <p>Björn W. Schuller received his diploma, doctoral degree, habilitation, and Adjunct Teaching Professor in Machine Intelligence and Signal Processing all in EE/IT from TUM in Munich/Germany. He is Full Professor of Artificial Intelligence and the Head of GLAM  - the Group on Language, Audio, & Music - at Imperial College London/UK, Full Professor and Chair of Embedded Intelligence for Health Care and Wellbeing at the University of Augsburg/Germany, co-founding CEO and current CSO of audEERING – an Audio Intelligence company based near Munich and in Berlin/Germany, Guest Professor at Southeast University in Nanjing/China and permanent Visiting Professor at HIT/China amongst other Professorships and Affiliations. Previous stays include Full Professor at the University of Passau/Germany, Key Researcher at Joanneum Research in Graz/Austria, and the CNRS-LIMSI in Orsay/France. He is a Fellow of the IEEE and Golden Core Awardee of the IEEE Computer Society, Fellow of the BCS, Fellow of the ISCA, President-Emeritus of the AAAC, and Senior Member of the ACM. He (co-)authored 1,000+ publications (40k+ citations, h-index=91), is Field Chief Editor of Frontiers in Digital Health and was Editor in Chief of the IEEE Transactions on Affective Computing amongst manifold further commitments and service to the community. His 30+ awards include having been honoured as one of 40 extraordinary scientists under the age of 40 by the WEF in 2015. First-in-the-field of Affective Computing and Sentiment analysis challenges such as AVEC, Interspeech ComParE, or MuSe have been initiated and by now organised overall more than 25 times by him. He is an ERC Starting and DFG Reinhart-Koselleck Grantee, and consultant of companies such as Barclays, GN, Huawei, Informetis, or Samsung.</h5>
                  {% endfor %}
                </div>
            </div>
        </div>
    </section>
